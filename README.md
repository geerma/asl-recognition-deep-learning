# American Sign Language (ASL) Alphabet Recognition using Deep Learning

[Report](ASL_Recognition_Final_Report.pdf)

[Jupyter Notebook](ASL_Recognition_Deep_Learning.ipynb)

## Abstract

Over 5% of the world’s population have moderate to severe
hearing loss, and much of this population in North America
learns American Sign Language (ASL) to communicate.
The learning and usage of sign language are not only useful
for those who are ‘hard of hearing’ or ‘deaf’, but also for
their family members and friends.
Unfortunately, sign language interpretation is not
always available - and some technologies that classify sign
language use expensive equipment like gloves with
embedded sensors. A deep learning model that can classify
ASL through images taken from a camera lens is a
convenient solution to this problem. This report explores the
use of both pre-trained and untrained deep learning models
such as ResNet, VGG-16, GoogleNet, and a custom CNN
model for an ASL fingerspelling dataset.
Our findings suggest that we received a testing
accuracy of 96.7%, 95.6%, and 94.6% for ResNet, VGG-16,
and GoogleNet respectively. Additionally, our custom CNN
model resulted in 90.8% testing accuracy.
